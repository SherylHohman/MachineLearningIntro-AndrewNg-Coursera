 Directory of S:\Classes\Coursera_MachineLearningIntro_AndrewNg\week5-NN_backPropogationAnd
CostFunction-ex4\ex4

[.]                          fmincg.m
[..]                         [lib]
checkNNGradients.m           nnCostFunction.m
computeNumericalGradient.m   predict.m
debugInitializeWeights.m     randInitializeWeights.m
displayData.m                sigmoid.m
ex4.m                        sigmoidGradient.m
ex4data1.mat                 submit.m
ex4weights.mat
              14 File(s)      7,620,739 bytes
               3 Dir(s)  65,630,752,768 bytes free
Loading and Visualizing Data ...
Program paused. Press enter to continue.

Loading Saved Neural Network Parameters ...

Feedforward Using Neural Network ...
Cost at parameters (loaded from ex4weights): 0.287629
(this value should be about 0.287629)

Program paused. Press enter to continue.

Checking Cost Function (w/ Regularization) ...
Cost at parameters (loaded from ex4weights): 0.383770
(this value should be about 0.383770)
Program paused. Press enter to continue.

....

If your backpropagation implementation is correct, then
the relative difference will be small (less than 1e-9).

Relative Difference: 2.33552e-011

Program paused. Press enter to continue.

>> cking Backpropagation (w/ Regularization) ...
>> -in computeNumGrad..
>> mgrad size: 38 x 1
>> etaSize: 38 x 1---------------------------------------------------------- Theta1: 5 x 4  The
>> : 3 x 6  in checkNNGrad..
>> qgradsize: 38 x 1
error: 'q' undefined near line 1 column 1
>> submit
== Submitting solutions | Neural Networks Learning...
Use token from last successful submission (sherylhohman@yahoo.com)? (Y/n): y
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100  1613  100   569  100  1044    372    683  0:00:01  0:00:01 --:--:--   847
== 1.6768e-002  -3.0498e-006
==                                   Part Name |     Score | Feedback
==                                   --------- |     ----- | --------
==               Feedforward and Cost Function |  30 /  30 | Nice work!
==                   Regularized Cost Function |  15 /  15 | Nice work!
==                            Sigmoid Gradient |   5 /   5 | Nice work!
==   Neural Network Gradient (Backpropagation) |  40 /  40 | Nice work!
==                        Regularized Gradient |   0 /  10 |
==                                   --------------------------------
==                                             |  90 / 100 |
==